---
phase: 02-performance-optimization
plan: 03
type: execute
wave: 3
depends_on:
  - 02-01
  - 02-02
files_modified:
  - .planning/lighthouse/
autonomous: false
requirements:
  - OPT-02

must_haves:
  truths:
    - "Lighthouse Performance score is >= 90 on all pages for both mobile and desktop"
    - "Before/after scores are documented with clear comparison showing improvement"
    - "All Core Web Vitals (LCP, CLS, INP) meet 'good' thresholds"
  artifacts:
    - path: ".planning/lighthouse/RESULTS.md"
      provides: "Before/after Lighthouse comparison with all pages and both presets"
      contains: "Before"
  key_links:
    - from: ".planning/lighthouse/RESULTS.md"
      to: ".planning/lighthouse/BASELINE.md"
      via: "References baseline scores for comparison"
      pattern: "baseline"
---

<objective>
Re-run Lighthouse on all pages after all optimizations from Plans 01 and 02 are applied, compare with the baseline, and document the before/after results. Verify the target of >= 90 Performance on all pages for both mobile and desktop.

Purpose: This is the proof that Phase 2 achieved its goal. Without documented before/after scores, there's no evidence the optimizations had measurable impact. The user explicitly requires >= 90 Performance on both mobile and desktop.

Output: Final Lighthouse reports in `.planning/lighthouse/`, a RESULTS.md with before/after comparison table, and user verification that scores meet the target.
</objective>

<execution_context>
@C:/Users/xndr/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/xndr/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-performance-optimization/02-CONTEXT.md
@.planning/phases/02-performance-optimization/02-01-SUMMARY.md
@.planning/phases/02-performance-optimization/02-02-SUMMARY.md
@.planning/lighthouse/BASELINE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run final Lighthouse measurements and document before/after comparison</name>
  <files>.planning/lighthouse/</files>
  <action>
Re-run Lighthouse on all pages after all Phase 2 optimizations are applied. Compare with baseline. Document results.

**1. Build and start the production server:**
```bash
npm run build && npm run start
```

**2. Run Lighthouse for each page on both mobile and desktop:**
Same pages as baseline: `/` (home), `/projects`, `/blog`, `/about-me`, `/contact`.

For each page:
```bash
npx lighthouse "http://localhost:3000{path}" --output=json --output=html \
  --output-path=".planning/lighthouse/final-{name}-mobile" \
  --chrome-flags="--headless=new"

npx lighthouse "http://localhost:3000{path}" --preset=desktop --output=json --output=html \
  --output-path=".planning/lighthouse/final-{name}-desktop" \
  --chrome-flags="--headless=new"
```

**3. Create `.planning/lighthouse/RESULTS.md` — Before/after comparison:**

Read the baseline scores from `.planning/lighthouse/BASELINE.md` and the final scores from the new JSON reports. Create a comparison table:

```markdown
# Lighthouse Results — Phase 2 Performance Optimization

**Measured:** {date}
**Baseline:** Pre-Phase 2 (from BASELINE.md)
**Final:** Post-Phase 2 (all optimizations applied)

## Performance Scores

| Page | Mobile Before | Mobile After | Delta | Desktop Before | Desktop After | Delta |
|------|--------------|-------------|-------|----------------|--------------|-------|
| Home | XX | XX | +X | XX | XX | +X |
| Projects | XX | XX | +X | XX | XX | +X |
| Blog | XX | XX | +X | XX | XX | +X |
| About Me | XX | XX | +X | XX | XX | +X |
| Contact | XX | XX | +X | XX | XX | +X |

## Core Web Vitals (Mobile)

| Page | LCP Before | LCP After | CLS Before | CLS After | INP Before | INP After |
|------|-----------|----------|-----------|---------|-----------|---------|
| Home | X.Xs | X.Xs | X.XX | X.XX | XXms | XXms |
| ... | ... | ... | ... | ... | ... | ... |

## Target Verification

- [ ] All mobile Performance scores >= 90
- [ ] All desktop Performance scores >= 90

## Changes Applied
- Removed framer-motion dependency (0KB impact — was already tree-shaken)
- Deleted dead code: particles.tsx, mouse.ts, Montserrat fonts (~4.3MB public assets)
- Fixed next/image sizes props on 4 files (reduced image download sizes)
- Restructured projects page with Suspense streaming (faster initial render)
- Set ISR revalidation to 5 minutes on projects route
- Added immutable cache headers for static assets
- Removed @next/swc workaround, cleaned tailwind.config.ts
```

**4. Assess results:**
- If ALL scores are >= 90: mark target checkboxes, proceed to checkpoint
- If any score is < 90: note which page and metric, identify the bottleneck from the Lighthouse report details (e.g., LCP image, unused JS, render-blocking resources), and apply the following remediation path:

**Remediation candidates if scores fall short (ordered by likely impact):**
  1. **LCP too high (> 2.5s):** Compress oversized source images (e.g., HeadshotInteractive/Thumbnail.png is 6MB — compress to < 500KB). Add `priority` to the LCP image on that page.
  2. **Large JS bundle / unused JS flagged:** Check if any large dependency crept in. Re-run `ANALYZE=true npm run build` and compare with the baseline BUNDLE-ANALYSIS.md. Consider dynamic importing heavy client components.
  3. **CLS too high (> 0.1):** Ensure all images have explicit width/height or `fill` with a sized container. Check that skeleton fallbacks match real content dimensions.
  4. **Render-blocking CSS:** Next.js should inline critical CSS automatically. If flagged, check for external stylesheet imports in `<head>`.
  5. **Font loading delay:** Verify `next/font/google` is configured with `display: 'swap'` (or `display: 'optional'` for non-critical fonts).

If a remediation fix is straightforward (< 15 min), apply it immediately, re-run Lighthouse on the affected page, and update RESULTS.md. If the fix requires significant work, document it in RESULTS.md under a "## Remaining Optimizations" section for a future gap-closure plan.

**5. Stop the background server.**
  </action>
  <verify>
- `.planning/lighthouse/RESULTS.md` exists with before/after comparison table
- At least 10 new JSON report files exist with `final-` prefix in `.planning/lighthouse/`
- The RESULTS.md table has numeric values for all pages and both presets
- Target verification checkboxes in RESULTS.md reflect actual scores
  </verify>
  <done>Final Lighthouse scores captured for all 5 pages on both mobile and desktop, before/after comparison documented in RESULTS.md with delta values and Core Web Vitals breakdown</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify Lighthouse scores meet >= 90 target</name>
  <files>.planning/lighthouse/RESULTS.md</files>
  <action>
Present the before/after Lighthouse results to the user for verification.

All Phase 2 performance optimizations have been applied and measured:
- Bundle cleanup (dead deps, fonts, components removed)
- Image optimization (sizes props on all next/image usages)
- Suspense streaming (projects page renders shell immediately)
- ISR + caching (5-min revalidation, immutable asset headers)

Final Lighthouse scores are documented in `.planning/lighthouse/RESULTS.md`.

**User verification steps:**
1. Open `.planning/lighthouse/RESULTS.md` and review the before/after comparison
2. Verify ALL Performance scores are >= 90 (both mobile and desktop)
3. Check the Core Web Vitals section for any "poor" or "needs improvement" metrics
4. Optionally: run `npm run build && npm run start` and open Chrome DevTools Lighthouse tab on any page to spot-check
5. Optionally: browse the site at `http://localhost:3000` and verify pages load correctly, no visual regressions

If any score is below 90, the RESULTS.md will note what further optimization is needed.
  </action>
  <verify>User confirms all scores >= 90 and site looks correct</verify>
  <done>User approved: all Lighthouse Performance scores >= 90 on both mobile and desktop, no visual regressions</done>
</task>

</tasks>

<verification>
- `.planning/lighthouse/RESULTS.md` contains a complete before/after comparison for all 5 pages on mobile and desktop
- All Performance scores are >= 90 (user-verified)
- Core Web Vitals (LCP, CLS, INP) are in "good" range
- No visual regressions on any page
</verification>

<success_criteria>
1. Lighthouse Performance score >= 90 on all pages for both mobile and desktop (OPT-02 satisfied)
2. Before/after scores documented with clear improvement deltas (OPT-01 + OPT-02 evidence)
3. User has verified the scores and approved the results
</success_criteria>

<output>
After completion, create `.planning/phases/02-performance-optimization/02-03-SUMMARY.md`
</output>
